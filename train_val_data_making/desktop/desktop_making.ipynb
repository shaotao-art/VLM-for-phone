{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('../')))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.file_utils import read_image, read_json, save_image, save_json, read_pkl\n",
    "from utils.draw_utils import draw_box\n",
    "from utils.helper_utils import float2_0_1000\n",
    "from prompts import all_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = '/home/shaotao/DATA/os-altas/os-altas-linux'\n",
    "ann_root = '/home/shaotao/PROJECTS/VLM_AND_PHONE/train_val_data_making/desktop/linux_patch_with_ocr_label.json'\n",
    "\n",
    "ele_per_diag = 10\n",
    "inst_type = 'func'\n",
    "out_json_p = f'linux_patch_ocr_train.json'\n",
    "prompt_type = 'ground_prompt_for_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_PROMPT = all_prompts[prompt_type]\n",
    "\n",
    "CONTINUE_PROMPT = \"\"\"## Instruction\n",
    "{instruction}\"\"\"\n",
    "\n",
    "\n",
    "df = pd.read_json(ann_root)\n",
    "num_turn_per_diag = 10\n",
    "import random\n",
    "random.seed(42)\n",
    "all_datas = []\n",
    "for img_idx, (g_name, g_df) in enumerate(df.groupby('img_name')):\n",
    "    img_p = os.path.join(img_root, g_name)\n",
    "    if img_idx % 50 == 0:\n",
    "        img = read_image(img_p)\n",
    "\n",
    "    conversation = []\n",
    "    count = 0\n",
    "    for ele_idx, ele in g_df.iterrows():\n",
    "        if count % num_turn_per_diag == 0 and count != 0:\n",
    "            count = 0\n",
    "            line = {'conversation': conversation, 'image_lst': [os.path.join(img_root, img_p)]}\n",
    "            all_datas.append(line)\n",
    "            conversation = []\n",
    "            if len(all_datas) % 50 == 0:\n",
    "                print(f'IDX: {len(all_datas)},  sample func_ann: {func_ann}')\n",
    "            \n",
    "        box = ele['box']\n",
    "        func_ann = ele['model_pred'].strip()\n",
    "        if 'Click to' in func_ann:\n",
    "            func_ann = func_ann.replace('Click to', '').strip()\n",
    "        if count == 0:   \n",
    "            prompt = INIT_PROMPT.format(instruction=func_ann)\n",
    "        else:\n",
    "            prompt = CONTINUE_PROMPT.format(instruction=func_ann)\n",
    "        count += 1\n",
    "            \n",
    "        x1, y1, x2, y2 = box\n",
    "        cent_x, cent_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "        pt = [cent_x, cent_y]\n",
    "        try:\n",
    "            pt = list(map(float2_0_1000, pt))\n",
    "        except Exception as e:\n",
    "            print('idx: ', g_name, e)\n",
    "            continue\n",
    "        ans = f'({pt[0]},{pt[1]})'\n",
    "        conversation.append({'from': 'human', 'value': prompt})\n",
    "        conversation.append({'from': 'gpt', 'value': ans})\n",
    "        if img_idx % 50 == 0:\n",
    "            img = draw_box(img, (x1, y1, x2, y2))\n",
    "            \n",
    "    if img_idx % 50 == 0:\n",
    "        save_image(img, f'tmp_{img_idx}.jpg')\n",
    "\n",
    "print('total data num: ', len(all_datas))\n",
    "save_json(all_datas, out_json_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = read_json('/home/shaotao/PROJECTS/VLM_AND_PHONE/train_val_data_making/desktop/linux_patch_ocr_train.json')\n",
    "print('data1: ', len(data1))\n",
    "data2 = read_json('/home/shaotao/PROJECTS/VLM_AND_PHONE/train_val_data_making/desktop/mac_patch_ocr_train.json')\n",
    "print('data2: ', len(data2))\n",
    "data1.extend(data2)\n",
    "print('data1: ', len(data1))\n",
    "save_json(data1, '/home/shaotao/PROJECTS/VLM_AND_PHONE/train_val_data_making/desktop/patch_ocr_train.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
